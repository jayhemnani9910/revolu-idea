# CAG Deep Research System - Environment Configuration
# Copy this file to `.env` and fill in your API keys.

# === LLM (API) Configuration ===
# Recommended for this repo: DeepSeek (OpenAI-compatible).
# - Use `deepseek-chat` for faster/cheaper runs (default).
# - Use `deepseek-reasoner` for deeper reasoning (slower/more expensive).
LLM_PROVIDER=deepseek
LLM_BASE_URL=https://api.deepseek.com
LLM_MODEL=deepseek-chat
LLM_API_KEY=your-api-key-here

# Alternative: Groq (OpenAI-compatible) endpoint.
# LLM_PROVIDER=groq
# LLM_BASE_URL=https://api.groq.com/openai/v1
# Use "auto" to use the built-in Groq model pool (guard/safeguard models are skipped),
# or provide a comma-separated list to control it.
# LLM_MODEL=auto
# LLM_API_KEY=your-groq-key-here

# === Ollama (local) Configuration (kept, but not used by default) ===
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen3:8b

# Generation parameters
TEMPERATURE=0.0
MAX_TOKENS=4096

# === Search Configuration ===
# Free option (no key): DuckDuckGo (may be rate-limited / less stable).
SEARCH_PROVIDER=duckduckgo

# Paid/high-quality options:
# SEARCH_PROVIDER=tavily
# TAVILY_API_KEY=tvly-your-tavily-key-here
# SEARCH_PROVIDER=exa
# EXA_API_KEY=your-exa-key-here

# === Research Parameters ===
MAX_RECURSION_DEPTH=5
MAX_INVESTIGATIONS_PER_EDGE=2

# === Storage Configuration ===
OUTPUT_DIR=output
